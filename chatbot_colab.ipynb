{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python383jvsc74a57bd03a7853f465984184c2db926f12cf0514f49bd82ebd08c64e7d47bb74214f72b4",
      "display_name": "Python 3.8.3 64-bit ('base': conda)"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2RjUhNsqY4L"
      },
      "source": [
        "import re\n",
        "import random\n",
        "data_path = \"human_text.txt\"\n",
        "data_path2 = \"robot_text.txt\"\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISZbWHSqAYt7"
      },
      "source": [
        "# Defining lines as a list of each line\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "  lines = f.read().split('\\n')\n",
        "with open(data_path2, 'r', encoding='utf-8') as f:\n",
        "  lines2 = f.read().split('\\n')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmJmd6chAYt8"
      },
      "source": [
        "lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in lines]\n",
        "lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]\n",
        "lines2 = [re.sub(r\"\\[\\w+\\]\",'',line) for line in lines2]\n",
        "lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines2]\n",
        "# Grouping lines by response pair\n",
        "pairs = list(zip(lines,lines2))\n",
        "#random.shuffle(pairs)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8WhW38QAYt9",
        "outputId": "f01bdb1b-e01b-4ab0-f448-f5f434874bf3"
      },
      "source": [
        "len(pairs)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2363"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3DW7hgpAYt_",
        "outputId": "6d0eb93c-f1fb-4892-b5f7-3e5081e47319"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "for line in pairs[:400]:\n",
        "  input_doc, target_doc = line[0], line[1]\n",
        "  # Appending each input sentence to input_docs\n",
        "  input_docs.append(input_doc)\n",
        "  # Splitting words from punctuation  \n",
        "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
        "  # Redefine target_doc below and append it to target_docs\n",
        "  target_doc = '<START> ' + target_doc + ' <END>'\n",
        "  target_docs.append(target_doc)\n",
        "  \n",
        "  # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
        "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "  for token in target_doc.split():\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "input_tokens = sorted(list(input_tokens))\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)\n",
        "print(num_decoder_tokens)\n",
        "print(num_encoder_tokens)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1003\n",
            "981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ra8g617AYuA"
      },
      "source": [
        "input_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict(\n",
        "    [(token, i) for i, token in enumerate(target_tokens)])\n",
        "\n",
        "reverse_input_features_dict = dict(\n",
        "    (i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict(\n",
        "    (i, token) for token, i in target_features_dict.items())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNRIMdJHAYuB"
      },
      "source": [
        "**Training setup**\n",
        "\n",
        "To train our seq2seq model we will use three matrices of one-hot vectors, Encoder input data, Decoder input data, and Decoder output data. The reason we are using two matrices for the Decoder is a method called teacher forcing which is used by the seq2seq model while training. What is the idea behind this? We have an input token from the previous timestep to help the model train for the current target token. Letâ€™s create these matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw7iFyTEFriu"
      },
      "source": [
        "# Maximum length of sentences in input and target documents\n",
        "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
        "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "\n",
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
        "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "    \n",
        "    for timestep, token in enumerate(target_doc.split()):\n",
        "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "        if timestep > 0:\n",
        "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPRH_kUNKaHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3d2d6e-576f-4810-a725-2e515c8c8772"
      },
      "source": [
        "print(pairs[:5])\n",
        "print('\\n')\n",
        "print('*'*20)\n",
        "print('\\n')\n",
        "print(input_docs[:5])\n",
        "print('\\n')\n",
        "print('*'*20)\n",
        "print('\\n')\n",
        "print(target_docs[:5])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('hi', 'hi there how are you'), ('oh thanks i m fine this is an evening in my timezone', 'here is afternoon'), ('how do you feel today tell me something about yourself', 'my name is rdany but you can call me dany the r means robot i hope we can be virtual friends'), ('how many virtual friends have you got', 'i have many but not enough to fully understand humans beings'), ('is that forbidden for you to tell the exact number', 'i ve talked with 143 users counting 7294 lines of text')]\n",
            "\n",
            "\n",
            "********************\n",
            "\n",
            "\n",
            "['hi', 'oh thanks i m fine this is an evening in my timezone', 'how do you feel today tell me something about yourself', 'how many virtual friends have you got', 'is that forbidden for you to tell the exact number']\n",
            "\n",
            "\n",
            "********************\n",
            "\n",
            "\n",
            "['<START> hi there how are you <END>', '<START> here is afternoon <END>', '<START> my name is rdany but you can call me dany the r means robot i hope we can be virtual friends <END>', '<START> i have many but not enough to fully understand humans beings <END>', '<START> i ve talked with 143 users counting 7294 lines of text <END>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQTwpYwCAYuC"
      },
      "source": [
        "\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZZcikCkFulO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0f330a-321e-47e1-dd5a-f1eafb38b4ea"
      },
      "source": [
        "\n",
        "#Dimensionality\n",
        "dimensionality = 256\n",
        "#The batch size and number of epochs\n",
        "batch_size = 10\n",
        "epochs = 600\n",
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "#Model\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "#Compiling\n",
        "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
        "#Training\n",
        "history = training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2,verbose = 1)\n",
        "training_model.save('my_model.h5')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/600\n",
            "32/32 [==============================] - 4s 37ms/step - loss: 1.3699 - accuracy: 0.0192 - val_loss: 1.3563 - val_accuracy: 0.0200\n",
            "Epoch 2/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1492 - accuracy: 0.0237 - val_loss: 1.3743 - val_accuracy: 0.0200\n",
            "Epoch 3/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.1286 - accuracy: 0.0236 - val_loss: 1.3960 - val_accuracy: 0.0200\n",
            "Epoch 4/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1389 - accuracy: 0.0238 - val_loss: 1.4135 - val_accuracy: 0.0200\n",
            "Epoch 5/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1769 - accuracy: 0.0242 - val_loss: 1.4324 - val_accuracy: 0.0200\n",
            "Epoch 6/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1536 - accuracy: 0.0250 - val_loss: 1.4584 - val_accuracy: 0.0200\n",
            "Epoch 7/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.0435 - accuracy: 0.0241 - val_loss: 1.4674 - val_accuracy: 0.0198\n",
            "Epoch 8/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.2223 - accuracy: 0.0235 - val_loss: 1.4858 - val_accuracy: 0.0200\n",
            "Epoch 9/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0994 - accuracy: 0.0255 - val_loss: 1.5021 - val_accuracy: 0.0203\n",
            "Epoch 10/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1229 - accuracy: 0.0245 - val_loss: 1.5179 - val_accuracy: 0.0207\n",
            "Epoch 11/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1313 - accuracy: 0.0246 - val_loss: 1.5401 - val_accuracy: 0.0205\n",
            "Epoch 12/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1916 - accuracy: 0.0254 - val_loss: 1.5525 - val_accuracy: 0.0207\n",
            "Epoch 13/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0931 - accuracy: 0.0264 - val_loss: 1.5669 - val_accuracy: 0.0207\n",
            "Epoch 14/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1874 - accuracy: 0.0257 - val_loss: 1.5856 - val_accuracy: 0.0213\n",
            "Epoch 15/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1886 - accuracy: 0.0254 - val_loss: 1.6000 - val_accuracy: 0.0210\n",
            "Epoch 16/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1110 - accuracy: 0.0239 - val_loss: 1.6092 - val_accuracy: 0.0210\n",
            "Epoch 17/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.2009 - accuracy: 0.0238 - val_loss: 1.6215 - val_accuracy: 0.0207\n",
            "Epoch 18/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1245 - accuracy: 0.0241 - val_loss: 1.6296 - val_accuracy: 0.0210\n",
            "Epoch 19/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1645 - accuracy: 0.0230 - val_loss: 1.6387 - val_accuracy: 0.0210\n",
            "Epoch 20/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1063 - accuracy: 0.0233 - val_loss: 1.6422 - val_accuracy: 0.0210\n",
            "Epoch 21/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1396 - accuracy: 0.0240 - val_loss: 1.6496 - val_accuracy: 0.0210\n",
            "Epoch 22/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1176 - accuracy: 0.0233 - val_loss: 1.6568 - val_accuracy: 0.0207\n",
            "Epoch 23/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0972 - accuracy: 0.0240 - val_loss: 1.6554 - val_accuracy: 0.0210\n",
            "Epoch 24/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1644 - accuracy: 0.0243 - val_loss: 1.6590 - val_accuracy: 0.0210\n",
            "Epoch 25/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1809 - accuracy: 0.0241 - val_loss: 1.6584 - val_accuracy: 0.0210\n",
            "Epoch 26/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1364 - accuracy: 0.0236 - val_loss: 1.6634 - val_accuracy: 0.0200\n",
            "Epoch 27/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1201 - accuracy: 0.0241 - val_loss: 1.6586 - val_accuracy: 0.0210\n",
            "Epoch 28/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1713 - accuracy: 0.0236 - val_loss: 1.6631 - val_accuracy: 0.0200\n",
            "Epoch 29/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0702 - accuracy: 0.0236 - val_loss: 1.6605 - val_accuracy: 0.0200\n",
            "Epoch 30/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1487 - accuracy: 0.0245 - val_loss: 1.6608 - val_accuracy: 0.0210\n",
            "Epoch 31/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1087 - accuracy: 0.0244 - val_loss: 1.6627 - val_accuracy: 0.0200\n",
            "Epoch 32/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1318 - accuracy: 0.0246 - val_loss: 1.6604 - val_accuracy: 0.0210\n",
            "Epoch 33/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1067 - accuracy: 0.0243 - val_loss: 1.6593 - val_accuracy: 0.0205\n",
            "Epoch 34/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.1057 - accuracy: 0.0233 - val_loss: 1.6608 - val_accuracy: 0.0198\n",
            "Epoch 35/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1262 - accuracy: 0.0235 - val_loss: 1.6623 - val_accuracy: 0.0200\n",
            "Epoch 36/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1555 - accuracy: 0.0243 - val_loss: 1.6637 - val_accuracy: 0.0200\n",
            "Epoch 37/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1355 - accuracy: 0.0236 - val_loss: 1.6595 - val_accuracy: 0.0203\n",
            "Epoch 38/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1607 - accuracy: 0.0243 - val_loss: 1.6613 - val_accuracy: 0.0210\n",
            "Epoch 39/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1279 - accuracy: 0.0231 - val_loss: 1.6612 - val_accuracy: 0.0200\n",
            "Epoch 40/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1548 - accuracy: 0.0250 - val_loss: 1.6651 - val_accuracy: 0.0200\n",
            "Epoch 41/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.2307 - accuracy: 0.0251 - val_loss: 1.6617 - val_accuracy: 0.0205\n",
            "Epoch 42/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1301 - accuracy: 0.0247 - val_loss: 1.6615 - val_accuracy: 0.0198\n",
            "Epoch 43/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0795 - accuracy: 0.0241 - val_loss: 1.6564 - val_accuracy: 0.0200\n",
            "Epoch 44/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1125 - accuracy: 0.0239 - val_loss: 1.6617 - val_accuracy: 0.0200\n",
            "Epoch 45/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1391 - accuracy: 0.0229 - val_loss: 1.6592 - val_accuracy: 0.0200\n",
            "Epoch 46/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1610 - accuracy: 0.0242 - val_loss: 1.6602 - val_accuracy: 0.0200\n",
            "Epoch 47/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1635 - accuracy: 0.0249 - val_loss: 1.6622 - val_accuracy: 0.0213\n",
            "Epoch 48/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1450 - accuracy: 0.0250 - val_loss: 1.6598 - val_accuracy: 0.0200\n",
            "Epoch 49/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1350 - accuracy: 0.0249 - val_loss: 1.6606 - val_accuracy: 0.0200\n",
            "Epoch 50/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1369 - accuracy: 0.0247 - val_loss: 1.6576 - val_accuracy: 0.0200\n",
            "Epoch 51/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1762 - accuracy: 0.0232 - val_loss: 1.6591 - val_accuracy: 0.0192\n",
            "Epoch 52/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1670 - accuracy: 0.0239 - val_loss: 1.6631 - val_accuracy: 0.0200\n",
            "Epoch 53/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1316 - accuracy: 0.0230 - val_loss: 1.6620 - val_accuracy: 0.0200\n",
            "Epoch 54/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1467 - accuracy: 0.0232 - val_loss: 1.6589 - val_accuracy: 0.0203\n",
            "Epoch 55/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1752 - accuracy: 0.0250 - val_loss: 1.6615 - val_accuracy: 0.0198\n",
            "Epoch 56/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1554 - accuracy: 0.0235 - val_loss: 1.6595 - val_accuracy: 0.0200\n",
            "Epoch 57/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1370 - accuracy: 0.0243 - val_loss: 1.6636 - val_accuracy: 0.0203\n",
            "Epoch 58/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1180 - accuracy: 0.0247 - val_loss: 1.6658 - val_accuracy: 0.0200\n",
            "Epoch 59/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1165 - accuracy: 0.0240 - val_loss: 1.6618 - val_accuracy: 0.0200\n",
            "Epoch 60/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1401 - accuracy: 0.0241 - val_loss: 1.6606 - val_accuracy: 0.0200\n",
            "Epoch 61/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.1334 - accuracy: 0.0246 - val_loss: 1.6623 - val_accuracy: 0.0200\n",
            "Epoch 62/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1306 - accuracy: 0.0240 - val_loss: 1.6615 - val_accuracy: 0.0203\n",
            "Epoch 63/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.2163 - accuracy: 0.0238 - val_loss: 1.6620 - val_accuracy: 0.0203\n",
            "Epoch 64/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1406 - accuracy: 0.0253 - val_loss: 1.6627 - val_accuracy: 0.0200\n",
            "Epoch 65/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1459 - accuracy: 0.0233 - val_loss: 1.6590 - val_accuracy: 0.0200\n",
            "Epoch 66/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1695 - accuracy: 0.0251 - val_loss: 1.6064 - val_accuracy: 0.0203\n",
            "Epoch 67/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1127 - accuracy: 0.0244 - val_loss: 1.6202 - val_accuracy: 0.0200\n",
            "Epoch 68/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1806 - accuracy: 0.0240 - val_loss: 1.6287 - val_accuracy: 0.0203\n",
            "Epoch 69/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1277 - accuracy: 0.0242 - val_loss: 1.6338 - val_accuracy: 0.0200\n",
            "Epoch 70/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1551 - accuracy: 0.0233 - val_loss: 1.6443 - val_accuracy: 0.0203\n",
            "Epoch 71/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1777 - accuracy: 0.0252 - val_loss: 1.6507 - val_accuracy: 0.0200\n",
            "Epoch 72/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1410 - accuracy: 0.0251 - val_loss: 1.6507 - val_accuracy: 0.0203\n",
            "Epoch 73/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1162 - accuracy: 0.0247 - val_loss: 1.6543 - val_accuracy: 0.0203\n",
            "Epoch 74/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1657 - accuracy: 0.0252 - val_loss: 1.6601 - val_accuracy: 0.0203\n",
            "Epoch 75/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.2017 - accuracy: 0.0239 - val_loss: 1.6600 - val_accuracy: 0.0200\n",
            "Epoch 76/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1605 - accuracy: 0.0245 - val_loss: 1.6597 - val_accuracy: 0.0203\n",
            "Epoch 77/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1183 - accuracy: 0.0242 - val_loss: 1.6639 - val_accuracy: 0.0192\n",
            "Epoch 78/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.1023 - accuracy: 0.0244 - val_loss: 1.6586 - val_accuracy: 0.0203\n",
            "Epoch 79/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1310 - accuracy: 0.0241 - val_loss: 1.6617 - val_accuracy: 0.0205\n",
            "Epoch 80/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0992 - accuracy: 0.0240 - val_loss: 1.6583 - val_accuracy: 0.0203\n",
            "Epoch 81/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1769 - accuracy: 0.0247 - val_loss: 1.6612 - val_accuracy: 0.0198\n",
            "Epoch 82/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.2369 - accuracy: 0.0250 - val_loss: 1.6629 - val_accuracy: 0.0200\n",
            "Epoch 83/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1272 - accuracy: 0.0233 - val_loss: 1.6627 - val_accuracy: 0.0198\n",
            "Epoch 84/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1687 - accuracy: 0.0246 - val_loss: 1.6607 - val_accuracy: 0.0198\n",
            "Epoch 85/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1785 - accuracy: 0.0248 - val_loss: 1.6627 - val_accuracy: 0.0203\n",
            "Epoch 86/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1464 - accuracy: 0.0243 - val_loss: 1.5990 - val_accuracy: 0.0203\n",
            "Epoch 87/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1788 - accuracy: 0.0248 - val_loss: 1.6072 - val_accuracy: 0.0200\n",
            "Epoch 88/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1980 - accuracy: 0.0250 - val_loss: 1.6201 - val_accuracy: 0.0200\n",
            "Epoch 89/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1480 - accuracy: 0.0253 - val_loss: 1.6269 - val_accuracy: 0.0207\n",
            "Epoch 90/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0553 - accuracy: 0.0237 - val_loss: 1.6400 - val_accuracy: 0.0192\n",
            "Epoch 91/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1724 - accuracy: 0.0260 - val_loss: 1.6422 - val_accuracy: 0.0200\n",
            "Epoch 92/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1687 - accuracy: 0.0259 - val_loss: 1.6519 - val_accuracy: 0.0200\n",
            "Epoch 93/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1396 - accuracy: 0.0244 - val_loss: 1.6545 - val_accuracy: 0.0203\n",
            "Epoch 94/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1010 - accuracy: 0.0242 - val_loss: 1.6561 - val_accuracy: 0.0203\n",
            "Epoch 95/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0894 - accuracy: 0.0251 - val_loss: 1.6592 - val_accuracy: 0.0203\n",
            "Epoch 96/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0862 - accuracy: 0.0245 - val_loss: 1.6584 - val_accuracy: 0.0203\n",
            "Epoch 97/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1454 - accuracy: 0.0254 - val_loss: 1.6638 - val_accuracy: 0.0198\n",
            "Epoch 98/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1290 - accuracy: 0.0237 - val_loss: 1.6636 - val_accuracy: 0.0198\n",
            "Epoch 99/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1948 - accuracy: 0.0229 - val_loss: 1.6545 - val_accuracy: 0.0195\n",
            "Epoch 100/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0803 - accuracy: 0.0237 - val_loss: 1.6477 - val_accuracy: 0.0203\n",
            "Epoch 101/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0814 - accuracy: 0.0242 - val_loss: 1.6535 - val_accuracy: 0.0200\n",
            "Epoch 102/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1439 - accuracy: 0.0252 - val_loss: 1.6579 - val_accuracy: 0.0203\n",
            "Epoch 103/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1486 - accuracy: 0.0245 - val_loss: 1.6690 - val_accuracy: 0.0198\n",
            "Epoch 104/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1108 - accuracy: 0.0240 - val_loss: 1.6627 - val_accuracy: 0.0207\n",
            "Epoch 105/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1087 - accuracy: 0.0247 - val_loss: 1.6622 - val_accuracy: 0.0203\n",
            "Epoch 106/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1154 - accuracy: 0.0257 - val_loss: 1.6612 - val_accuracy: 0.0203\n",
            "Epoch 107/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1433 - accuracy: 0.0252 - val_loss: 1.6625 - val_accuracy: 0.0203\n",
            "Epoch 108/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1453 - accuracy: 0.0250 - val_loss: 1.5577 - val_accuracy: 0.0203\n",
            "Epoch 109/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.1252 - accuracy: 0.0247 - val_loss: 1.5648 - val_accuracy: 0.0203\n",
            "Epoch 110/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1318 - accuracy: 0.0245 - val_loss: 1.5799 - val_accuracy: 0.0203\n",
            "Epoch 111/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1278 - accuracy: 0.0243 - val_loss: 1.5941 - val_accuracy: 0.0203\n",
            "Epoch 112/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0813 - accuracy: 0.0257 - val_loss: 1.6070 - val_accuracy: 0.0210\n",
            "Epoch 113/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1680 - accuracy: 0.0255 - val_loss: 1.6203 - val_accuracy: 0.0207\n",
            "Epoch 114/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1126 - accuracy: 0.0253 - val_loss: 1.6310 - val_accuracy: 0.0200\n",
            "Epoch 115/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1617 - accuracy: 0.0245 - val_loss: 1.6465 - val_accuracy: 0.0195\n",
            "Epoch 116/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1383 - accuracy: 0.0225 - val_loss: 1.6360 - val_accuracy: 0.0198\n",
            "Epoch 117/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1458 - accuracy: 0.0248 - val_loss: 1.6381 - val_accuracy: 0.0207\n",
            "Epoch 118/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1144 - accuracy: 0.0261 - val_loss: 1.6458 - val_accuracy: 0.0210\n",
            "Epoch 119/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1769 - accuracy: 0.0261 - val_loss: 1.6510 - val_accuracy: 0.0205\n",
            "Epoch 120/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1087 - accuracy: 0.0257 - val_loss: 1.6478 - val_accuracy: 0.0207\n",
            "Epoch 121/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1053 - accuracy: 0.0249 - val_loss: 1.6554 - val_accuracy: 0.0205\n",
            "Epoch 122/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1876 - accuracy: 0.0267 - val_loss: 1.6575 - val_accuracy: 0.0210\n",
            "Epoch 123/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1629 - accuracy: 0.0266 - val_loss: 1.6623 - val_accuracy: 0.0205\n",
            "Epoch 124/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1614 - accuracy: 0.0256 - val_loss: 1.6628 - val_accuracy: 0.0200\n",
            "Epoch 125/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1469 - accuracy: 0.0265 - val_loss: 1.6673 - val_accuracy: 0.0205\n",
            "Epoch 126/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1131 - accuracy: 0.0256 - val_loss: 1.6633 - val_accuracy: 0.0213\n",
            "Epoch 127/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0883 - accuracy: 0.0256 - val_loss: 1.6649 - val_accuracy: 0.0210\n",
            "Epoch 128/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.2072 - accuracy: 0.0260 - val_loss: 1.6636 - val_accuracy: 0.0213\n",
            "Epoch 129/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1760 - accuracy: 0.0262 - val_loss: 1.6680 - val_accuracy: 0.0205\n",
            "Epoch 130/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1398 - accuracy: 0.0259 - val_loss: 1.6692 - val_accuracy: 0.0203\n",
            "Epoch 131/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0879 - accuracy: 0.0253 - val_loss: 1.6658 - val_accuracy: 0.0203\n",
            "Epoch 132/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0915 - accuracy: 0.0258 - val_loss: 1.6703 - val_accuracy: 0.0207\n",
            "Epoch 133/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1474 - accuracy: 0.0252 - val_loss: 1.6657 - val_accuracy: 0.0210\n",
            "Epoch 134/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1566 - accuracy: 0.0260 - val_loss: 1.6679 - val_accuracy: 0.0205\n",
            "Epoch 135/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1503 - accuracy: 0.0276 - val_loss: 1.6659 - val_accuracy: 0.0207\n",
            "Epoch 136/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0706 - accuracy: 0.0253 - val_loss: 1.6659 - val_accuracy: 0.0213\n",
            "Epoch 137/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1679 - accuracy: 0.0260 - val_loss: 1.6691 - val_accuracy: 0.0217\n",
            "Epoch 138/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0714 - accuracy: 0.0281 - val_loss: 1.6634 - val_accuracy: 0.0213\n",
            "Epoch 139/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1684 - accuracy: 0.0271 - val_loss: 1.6649 - val_accuracy: 0.0215\n",
            "Epoch 140/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1680 - accuracy: 0.0268 - val_loss: 1.6655 - val_accuracy: 0.0210\n",
            "Epoch 141/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1958 - accuracy: 0.0278 - val_loss: 1.6611 - val_accuracy: 0.0217\n",
            "Epoch 142/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1252 - accuracy: 0.0283 - val_loss: 1.6658 - val_accuracy: 0.0215\n",
            "Epoch 143/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0886 - accuracy: 0.0259 - val_loss: 1.6646 - val_accuracy: 0.0205\n",
            "Epoch 144/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1371 - accuracy: 0.0264 - val_loss: 1.6710 - val_accuracy: 0.0200\n",
            "Epoch 145/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.2109 - accuracy: 0.0262 - val_loss: 1.6637 - val_accuracy: 0.0213\n",
            "Epoch 146/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0444 - accuracy: 0.0264 - val_loss: 1.6739 - val_accuracy: 0.0205\n",
            "Epoch 147/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0544 - accuracy: 0.0272 - val_loss: 1.6653 - val_accuracy: 0.0210\n",
            "Epoch 148/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1491 - accuracy: 0.0282 - val_loss: 1.6646 - val_accuracy: 0.0213\n",
            "Epoch 149/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1215 - accuracy: 0.0269 - val_loss: 1.6679 - val_accuracy: 0.0210\n",
            "Epoch 150/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0906 - accuracy: 0.0268 - val_loss: 1.6656 - val_accuracy: 0.0213\n",
            "Epoch 151/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1277 - accuracy: 0.0273 - val_loss: 1.6698 - val_accuracy: 0.0205\n",
            "Epoch 152/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1491 - accuracy: 0.0264 - val_loss: 1.6647 - val_accuracy: 0.0210\n",
            "Epoch 153/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1052 - accuracy: 0.0275 - val_loss: 1.6735 - val_accuracy: 0.0205\n",
            "Epoch 154/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1356 - accuracy: 0.0257 - val_loss: 1.6641 - val_accuracy: 0.0210\n",
            "Epoch 155/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0869 - accuracy: 0.0266 - val_loss: 1.6762 - val_accuracy: 0.0210\n",
            "Epoch 156/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1593 - accuracy: 0.0282 - val_loss: 1.6631 - val_accuracy: 0.0215\n",
            "Epoch 157/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0671 - accuracy: 0.0268 - val_loss: 1.6626 - val_accuracy: 0.0213\n",
            "Epoch 158/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1373 - accuracy: 0.0289 - val_loss: 1.6628 - val_accuracy: 0.0217\n",
            "Epoch 159/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1456 - accuracy: 0.0273 - val_loss: 1.6644 - val_accuracy: 0.0210\n",
            "Epoch 160/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1435 - accuracy: 0.0263 - val_loss: 1.6904 - val_accuracy: 0.0207\n",
            "Epoch 161/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0871 - accuracy: 0.0272 - val_loss: 1.6691 - val_accuracy: 0.0213\n",
            "Epoch 162/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1097 - accuracy: 0.0278 - val_loss: 1.6634 - val_accuracy: 0.0207\n",
            "Epoch 163/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0532 - accuracy: 0.0284 - val_loss: 1.6677 - val_accuracy: 0.0210\n",
            "Epoch 164/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1157 - accuracy: 0.0278 - val_loss: 1.6679 - val_accuracy: 0.0210\n",
            "Epoch 165/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0843 - accuracy: 0.0278 - val_loss: 1.6718 - val_accuracy: 0.0213\n",
            "Epoch 166/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1434 - accuracy: 0.0291 - val_loss: 1.6689 - val_accuracy: 0.0215\n",
            "Epoch 167/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1174 - accuracy: 0.0286 - val_loss: 1.6741 - val_accuracy: 0.0210\n",
            "Epoch 168/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1112 - accuracy: 0.0280 - val_loss: 1.6668 - val_accuracy: 0.0213\n",
            "Epoch 169/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0899 - accuracy: 0.0275 - val_loss: 1.6664 - val_accuracy: 0.0215\n",
            "Epoch 170/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1586 - accuracy: 0.0283 - val_loss: 1.6694 - val_accuracy: 0.0210\n",
            "Epoch 171/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0986 - accuracy: 0.0274 - val_loss: 1.6805 - val_accuracy: 0.0200\n",
            "Epoch 172/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1590 - accuracy: 0.0288 - val_loss: 1.6745 - val_accuracy: 0.0213\n",
            "Epoch 173/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1034 - accuracy: 0.0287 - val_loss: 1.6805 - val_accuracy: 0.0203\n",
            "Epoch 174/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1877 - accuracy: 0.0292 - val_loss: 1.6714 - val_accuracy: 0.0210\n",
            "Epoch 175/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0902 - accuracy: 0.0286 - val_loss: 1.6687 - val_accuracy: 0.0215\n",
            "Epoch 176/600\n",
            "32/32 [==============================] - 1s 17ms/step - loss: 1.1129 - accuracy: 0.0284 - val_loss: 1.6765 - val_accuracy: 0.0213\n",
            "Epoch 177/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1025 - accuracy: 0.0285 - val_loss: 1.6671 - val_accuracy: 0.0215\n",
            "Epoch 178/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1413 - accuracy: 0.0307 - val_loss: 1.6671 - val_accuracy: 0.0215\n",
            "Epoch 179/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1033 - accuracy: 0.0301 - val_loss: 1.6711 - val_accuracy: 0.0205\n",
            "Epoch 180/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0888 - accuracy: 0.0288 - val_loss: 1.6785 - val_accuracy: 0.0210\n",
            "Epoch 181/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1121 - accuracy: 0.0287 - val_loss: 1.6772 - val_accuracy: 0.0207\n",
            "Epoch 182/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1122 - accuracy: 0.0307 - val_loss: 1.6711 - val_accuracy: 0.0203\n",
            "Epoch 183/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0608 - accuracy: 0.0297 - val_loss: 1.6761 - val_accuracy: 0.0205\n",
            "Epoch 184/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1853 - accuracy: 0.0312 - val_loss: 1.6729 - val_accuracy: 0.0200\n",
            "Epoch 185/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0823 - accuracy: 0.0284 - val_loss: 1.6824 - val_accuracy: 0.0188\n",
            "Epoch 186/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1387 - accuracy: 0.0284 - val_loss: 1.6704 - val_accuracy: 0.0203\n",
            "Epoch 187/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0397 - accuracy: 0.0297 - val_loss: 1.6669 - val_accuracy: 0.0210\n",
            "Epoch 188/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1103 - accuracy: 0.0290 - val_loss: 1.6666 - val_accuracy: 0.0220\n",
            "Epoch 189/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1815 - accuracy: 0.0310 - val_loss: 1.6681 - val_accuracy: 0.0207\n",
            "Epoch 190/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1431 - accuracy: 0.0285 - val_loss: 1.6694 - val_accuracy: 0.0215\n",
            "Epoch 191/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0608 - accuracy: 0.0289 - val_loss: 1.6689 - val_accuracy: 0.0215\n",
            "Epoch 192/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0267 - accuracy: 0.0300 - val_loss: 1.6778 - val_accuracy: 0.0205\n",
            "Epoch 193/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0678 - accuracy: 0.0310 - val_loss: 1.6684 - val_accuracy: 0.0207\n",
            "Epoch 194/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1040 - accuracy: 0.0309 - val_loss: 1.6793 - val_accuracy: 0.0200\n",
            "Epoch 195/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1185 - accuracy: 0.0313 - val_loss: 1.6757 - val_accuracy: 0.0203\n",
            "Epoch 196/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0725 - accuracy: 0.0315 - val_loss: 1.6783 - val_accuracy: 0.0192\n",
            "Epoch 197/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0602 - accuracy: 0.0289 - val_loss: 1.6714 - val_accuracy: 0.0195\n",
            "Epoch 198/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1124 - accuracy: 0.0282 - val_loss: 1.6784 - val_accuracy: 0.0192\n",
            "Epoch 199/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1792 - accuracy: 0.0313 - val_loss: 1.6691 - val_accuracy: 0.0195\n",
            "Epoch 200/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1662 - accuracy: 0.0298 - val_loss: 1.6798 - val_accuracy: 0.0205\n",
            "Epoch 201/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0745 - accuracy: 0.0301 - val_loss: 1.6802 - val_accuracy: 0.0195\n",
            "Epoch 202/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0780 - accuracy: 0.0316 - val_loss: 1.6778 - val_accuracy: 0.0192\n",
            "Epoch 203/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0841 - accuracy: 0.0302 - val_loss: 1.6745 - val_accuracy: 0.0203\n",
            "Epoch 204/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0764 - accuracy: 0.0310 - val_loss: 1.6749 - val_accuracy: 0.0210\n",
            "Epoch 205/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1172 - accuracy: 0.0306 - val_loss: 1.6826 - val_accuracy: 0.0192\n",
            "Epoch 206/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0792 - accuracy: 0.0307 - val_loss: 1.6787 - val_accuracy: 0.0198\n",
            "Epoch 207/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0237 - accuracy: 0.0317 - val_loss: 1.6827 - val_accuracy: 0.0188\n",
            "Epoch 208/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1016 - accuracy: 0.0306 - val_loss: 1.6728 - val_accuracy: 0.0190\n",
            "Epoch 209/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0585 - accuracy: 0.0316 - val_loss: 1.6805 - val_accuracy: 0.0195\n",
            "Epoch 210/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0746 - accuracy: 0.0333 - val_loss: 1.6790 - val_accuracy: 0.0195\n",
            "Epoch 211/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1043 - accuracy: 0.0315 - val_loss: 1.6866 - val_accuracy: 0.0200\n",
            "Epoch 212/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1330 - accuracy: 0.0324 - val_loss: 1.6708 - val_accuracy: 0.0205\n",
            "Epoch 213/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0772 - accuracy: 0.0322 - val_loss: 1.6847 - val_accuracy: 0.0200\n",
            "Epoch 214/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0521 - accuracy: 0.0314 - val_loss: 1.6779 - val_accuracy: 0.0203\n",
            "Epoch 215/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1117 - accuracy: 0.0321 - val_loss: 1.6825 - val_accuracy: 0.0190\n",
            "Epoch 216/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0659 - accuracy: 0.0317 - val_loss: 1.6797 - val_accuracy: 0.0195\n",
            "Epoch 217/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0790 - accuracy: 0.0349 - val_loss: 1.6810 - val_accuracy: 0.0195\n",
            "Epoch 218/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1008 - accuracy: 0.0296 - val_loss: 1.6786 - val_accuracy: 0.0203\n",
            "Epoch 219/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1202 - accuracy: 0.0330 - val_loss: 1.6726 - val_accuracy: 0.0217\n",
            "Epoch 220/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0521 - accuracy: 0.0315 - val_loss: 1.6772 - val_accuracy: 0.0198\n",
            "Epoch 221/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1031 - accuracy: 0.0341 - val_loss: 1.6770 - val_accuracy: 0.0217\n",
            "Epoch 222/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0656 - accuracy: 0.0318 - val_loss: 1.6781 - val_accuracy: 0.0192\n",
            "Epoch 223/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1029 - accuracy: 0.0337 - val_loss: 1.6767 - val_accuracy: 0.0203\n",
            "Epoch 224/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0107 - accuracy: 0.0341 - val_loss: 1.6763 - val_accuracy: 0.0207\n",
            "Epoch 225/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1714 - accuracy: 0.0332 - val_loss: 1.6806 - val_accuracy: 0.0205\n",
            "Epoch 226/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1403 - accuracy: 0.0327 - val_loss: 1.6763 - val_accuracy: 0.0200\n",
            "Epoch 227/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0426 - accuracy: 0.0323 - val_loss: 1.6810 - val_accuracy: 0.0185\n",
            "Epoch 228/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0717 - accuracy: 0.0326 - val_loss: 1.6826 - val_accuracy: 0.0198\n",
            "Epoch 229/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0877 - accuracy: 0.0324 - val_loss: 1.6815 - val_accuracy: 0.0192\n",
            "Epoch 230/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1093 - accuracy: 0.0325 - val_loss: 1.6822 - val_accuracy: 0.0192\n",
            "Epoch 231/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1242 - accuracy: 0.0347 - val_loss: 1.6803 - val_accuracy: 0.0203\n",
            "Epoch 232/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0813 - accuracy: 0.0327 - val_loss: 1.6859 - val_accuracy: 0.0210\n",
            "Epoch 233/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1376 - accuracy: 0.0333 - val_loss: 1.6795 - val_accuracy: 0.0198\n",
            "Epoch 234/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0739 - accuracy: 0.0340 - val_loss: 1.6829 - val_accuracy: 0.0205\n",
            "Epoch 235/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9986 - accuracy: 0.0334 - val_loss: 1.6833 - val_accuracy: 0.0207\n",
            "Epoch 236/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0370 - accuracy: 0.0343 - val_loss: 1.6833 - val_accuracy: 0.0195\n",
            "Epoch 237/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0990 - accuracy: 0.0335 - val_loss: 1.6864 - val_accuracy: 0.0203\n",
            "Epoch 238/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0884 - accuracy: 0.0322 - val_loss: 1.6822 - val_accuracy: 0.0200\n",
            "Epoch 239/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0859 - accuracy: 0.0347 - val_loss: 1.6868 - val_accuracy: 0.0198\n",
            "Epoch 240/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1738 - accuracy: 0.0336 - val_loss: 1.6861 - val_accuracy: 0.0192\n",
            "Epoch 241/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0581 - accuracy: 0.0338 - val_loss: 1.6863 - val_accuracy: 0.0195\n",
            "Epoch 242/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0929 - accuracy: 0.0346 - val_loss: 1.6830 - val_accuracy: 0.0192\n",
            "Epoch 243/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0509 - accuracy: 0.0343 - val_loss: 1.6835 - val_accuracy: 0.0198\n",
            "Epoch 244/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0691 - accuracy: 0.0339 - val_loss: 1.6964 - val_accuracy: 0.0192\n",
            "Epoch 245/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0057 - accuracy: 0.0324 - val_loss: 1.6854 - val_accuracy: 0.0207\n",
            "Epoch 246/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1127 - accuracy: 0.0311 - val_loss: 1.6761 - val_accuracy: 0.0207\n",
            "Epoch 247/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1252 - accuracy: 0.0347 - val_loss: 1.6926 - val_accuracy: 0.0210\n",
            "Epoch 248/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1288 - accuracy: 0.0348 - val_loss: 1.7034 - val_accuracy: 0.0192\n",
            "Epoch 249/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0630 - accuracy: 0.0344 - val_loss: 1.6882 - val_accuracy: 0.0203\n",
            "Epoch 250/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0892 - accuracy: 0.0351 - val_loss: 1.6923 - val_accuracy: 0.0203\n",
            "Epoch 251/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1326 - accuracy: 0.0350 - val_loss: 1.6943 - val_accuracy: 0.0200\n",
            "Epoch 252/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0266 - accuracy: 0.0327 - val_loss: 1.6857 - val_accuracy: 0.0200\n",
            "Epoch 253/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0407 - accuracy: 0.0343 - val_loss: 1.6894 - val_accuracy: 0.0203\n",
            "Epoch 254/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0396 - accuracy: 0.0352 - val_loss: 1.6899 - val_accuracy: 0.0195\n",
            "Epoch 255/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.1668 - accuracy: 0.0333 - val_loss: 1.6912 - val_accuracy: 0.0200\n",
            "Epoch 256/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0795 - accuracy: 0.0354 - val_loss: 1.6915 - val_accuracy: 0.0203\n",
            "Epoch 257/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0751 - accuracy: 0.0339 - val_loss: 1.6896 - val_accuracy: 0.0213\n",
            "Epoch 258/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0434 - accuracy: 0.0340 - val_loss: 1.6941 - val_accuracy: 0.0198\n",
            "Epoch 259/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0823 - accuracy: 0.0345 - val_loss: 1.6996 - val_accuracy: 0.0205\n",
            "Epoch 260/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0161 - accuracy: 0.0349 - val_loss: 1.6815 - val_accuracy: 0.0205\n",
            "Epoch 261/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9623 - accuracy: 0.0330 - val_loss: 1.6900 - val_accuracy: 0.0205\n",
            "Epoch 262/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0379 - accuracy: 0.0361 - val_loss: 1.7000 - val_accuracy: 0.0207\n",
            "Epoch 263/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0759 - accuracy: 0.0363 - val_loss: 1.6916 - val_accuracy: 0.0210\n",
            "Epoch 264/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0660 - accuracy: 0.0340 - val_loss: 1.6870 - val_accuracy: 0.0217\n",
            "Epoch 265/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0530 - accuracy: 0.0362 - val_loss: 1.6930 - val_accuracy: 0.0198\n",
            "Epoch 266/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0630 - accuracy: 0.0380 - val_loss: 1.6965 - val_accuracy: 0.0200\n",
            "Epoch 267/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0056 - accuracy: 0.0364 - val_loss: 1.6921 - val_accuracy: 0.0205\n",
            "Epoch 268/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1076 - accuracy: 0.0370 - val_loss: 1.6930 - val_accuracy: 0.0205\n",
            "Epoch 269/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0195 - accuracy: 0.0375 - val_loss: 1.6932 - val_accuracy: 0.0203\n",
            "Epoch 270/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0456 - accuracy: 0.0355 - val_loss: 1.6951 - val_accuracy: 0.0207\n",
            "Epoch 271/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0670 - accuracy: 0.0383 - val_loss: 1.7074 - val_accuracy: 0.0188\n",
            "Epoch 272/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0050 - accuracy: 0.0356 - val_loss: 1.7004 - val_accuracy: 0.0210\n",
            "Epoch 273/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0172 - accuracy: 0.0363 - val_loss: 1.6951 - val_accuracy: 0.0198\n",
            "Epoch 274/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0205 - accuracy: 0.0360 - val_loss: 1.6917 - val_accuracy: 0.0203\n",
            "Epoch 275/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0255 - accuracy: 0.0374 - val_loss: 1.6859 - val_accuracy: 0.0205\n",
            "Epoch 276/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0382 - accuracy: 0.0353 - val_loss: 1.6981 - val_accuracy: 0.0205\n",
            "Epoch 277/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0361 - accuracy: 0.0366 - val_loss: 1.6929 - val_accuracy: 0.0207\n",
            "Epoch 278/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0188 - accuracy: 0.0358 - val_loss: 1.7010 - val_accuracy: 0.0217\n",
            "Epoch 279/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0792 - accuracy: 0.0375 - val_loss: 1.7034 - val_accuracy: 0.0198\n",
            "Epoch 280/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0073 - accuracy: 0.0374 - val_loss: 1.6975 - val_accuracy: 0.0200\n",
            "Epoch 281/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0838 - accuracy: 0.0366 - val_loss: 1.7035 - val_accuracy: 0.0207\n",
            "Epoch 282/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0627 - accuracy: 0.0368 - val_loss: 1.6933 - val_accuracy: 0.0213\n",
            "Epoch 283/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0027 - accuracy: 0.0369 - val_loss: 1.7018 - val_accuracy: 0.0203\n",
            "Epoch 284/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0256 - accuracy: 0.0378 - val_loss: 1.6924 - val_accuracy: 0.0217\n",
            "Epoch 285/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9877 - accuracy: 0.0385 - val_loss: 1.7042 - val_accuracy: 0.0195\n",
            "Epoch 286/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0994 - accuracy: 0.0366 - val_loss: 1.7034 - val_accuracy: 0.0200\n",
            "Epoch 287/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0868 - accuracy: 0.0362 - val_loss: 1.7007 - val_accuracy: 0.0207\n",
            "Epoch 288/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0128 - accuracy: 0.0371 - val_loss: 1.6956 - val_accuracy: 0.0207\n",
            "Epoch 289/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0324 - accuracy: 0.0382 - val_loss: 1.7028 - val_accuracy: 0.0207\n",
            "Epoch 290/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0497 - accuracy: 0.0357 - val_loss: 1.6989 - val_accuracy: 0.0215\n",
            "Epoch 291/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1207 - accuracy: 0.0403 - val_loss: 1.6980 - val_accuracy: 0.0213\n",
            "Epoch 292/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0218 - accuracy: 0.0371 - val_loss: 1.7001 - val_accuracy: 0.0213\n",
            "Epoch 293/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0561 - accuracy: 0.0375 - val_loss: 1.6981 - val_accuracy: 0.0210\n",
            "Epoch 294/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0432 - accuracy: 0.0370 - val_loss: 1.7065 - val_accuracy: 0.0215\n",
            "Epoch 295/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.1053 - accuracy: 0.0373 - val_loss: 1.6972 - val_accuracy: 0.0198\n",
            "Epoch 296/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0913 - accuracy: 0.0370 - val_loss: 1.6956 - val_accuracy: 0.0217\n",
            "Epoch 297/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0271 - accuracy: 0.0379 - val_loss: 1.6949 - val_accuracy: 0.0215\n",
            "Epoch 298/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9836 - accuracy: 0.0364 - val_loss: 1.6941 - val_accuracy: 0.0215\n",
            "Epoch 299/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0019 - accuracy: 0.0392 - val_loss: 1.6905 - val_accuracy: 0.0213\n",
            "Epoch 300/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9548 - accuracy: 0.0389 - val_loss: 1.6991 - val_accuracy: 0.0207\n",
            "Epoch 301/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0517 - accuracy: 0.0380 - val_loss: 1.6995 - val_accuracy: 0.0210\n",
            "Epoch 302/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 1.0112 - accuracy: 0.0374 - val_loss: 1.6989 - val_accuracy: 0.0210\n",
            "Epoch 303/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9876 - accuracy: 0.0357 - val_loss: 1.6934 - val_accuracy: 0.0210\n",
            "Epoch 304/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0422 - accuracy: 0.0390 - val_loss: 1.6925 - val_accuracy: 0.0210\n",
            "Epoch 305/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9403 - accuracy: 0.0366 - val_loss: 1.7024 - val_accuracy: 0.0200\n",
            "Epoch 306/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0220 - accuracy: 0.0398 - val_loss: 1.7025 - val_accuracy: 0.0215\n",
            "Epoch 307/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0007 - accuracy: 0.0389 - val_loss: 1.6990 - val_accuracy: 0.0210\n",
            "Epoch 308/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0171 - accuracy: 0.0389 - val_loss: 1.6918 - val_accuracy: 0.0207\n",
            "Epoch 309/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0239 - accuracy: 0.0402 - val_loss: 1.6996 - val_accuracy: 0.0210\n",
            "Epoch 310/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0159 - accuracy: 0.0383 - val_loss: 1.6988 - val_accuracy: 0.0210\n",
            "Epoch 311/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9915 - accuracy: 0.0409 - val_loss: 1.7026 - val_accuracy: 0.0205\n",
            "Epoch 312/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9533 - accuracy: 0.0407 - val_loss: 1.6931 - val_accuracy: 0.0205\n",
            "Epoch 313/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9745 - accuracy: 0.0407 - val_loss: 1.7024 - val_accuracy: 0.0215\n",
            "Epoch 314/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9958 - accuracy: 0.0408 - val_loss: 1.7014 - val_accuracy: 0.0207\n",
            "Epoch 315/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9439 - accuracy: 0.0402 - val_loss: 1.6930 - val_accuracy: 0.0223\n",
            "Epoch 316/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0575 - accuracy: 0.0417 - val_loss: 1.7053 - val_accuracy: 0.0200\n",
            "Epoch 317/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0042 - accuracy: 0.0406 - val_loss: 1.6981 - val_accuracy: 0.0200\n",
            "Epoch 318/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0063 - accuracy: 0.0410 - val_loss: 1.7054 - val_accuracy: 0.0195\n",
            "Epoch 319/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 1.0796 - accuracy: 0.0442 - val_loss: 1.7040 - val_accuracy: 0.0200\n",
            "Epoch 320/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0428 - accuracy: 0.0398 - val_loss: 1.7059 - val_accuracy: 0.0203\n",
            "Epoch 321/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9922 - accuracy: 0.0406 - val_loss: 1.7009 - val_accuracy: 0.0220\n",
            "Epoch 322/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0010 - accuracy: 0.0405 - val_loss: 1.7029 - val_accuracy: 0.0195\n",
            "Epoch 323/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0404 - accuracy: 0.0410 - val_loss: 1.7150 - val_accuracy: 0.0205\n",
            "Epoch 324/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9469 - accuracy: 0.0404 - val_loss: 1.6961 - val_accuracy: 0.0207\n",
            "Epoch 325/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9589 - accuracy: 0.0409 - val_loss: 1.7012 - val_accuracy: 0.0198\n",
            "Epoch 326/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0056 - accuracy: 0.0435 - val_loss: 1.7014 - val_accuracy: 0.0215\n",
            "Epoch 327/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9631 - accuracy: 0.0434 - val_loss: 1.7104 - val_accuracy: 0.0203\n",
            "Epoch 328/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9461 - accuracy: 0.0405 - val_loss: 1.7069 - val_accuracy: 0.0205\n",
            "Epoch 329/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9341 - accuracy: 0.0415 - val_loss: 1.7065 - val_accuracy: 0.0217\n",
            "Epoch 330/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9888 - accuracy: 0.0430 - val_loss: 1.7193 - val_accuracy: 0.0198\n",
            "Epoch 331/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0229 - accuracy: 0.0425 - val_loss: 1.7047 - val_accuracy: 0.0207\n",
            "Epoch 332/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0324 - accuracy: 0.0430 - val_loss: 1.7050 - val_accuracy: 0.0203\n",
            "Epoch 333/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9788 - accuracy: 0.0423 - val_loss: 1.7106 - val_accuracy: 0.0207\n",
            "Epoch 334/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0006 - accuracy: 0.0431 - val_loss: 1.7103 - val_accuracy: 0.0205\n",
            "Epoch 335/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9385 - accuracy: 0.0409 - val_loss: 1.7073 - val_accuracy: 0.0210\n",
            "Epoch 336/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9066 - accuracy: 0.0440 - val_loss: 1.7025 - val_accuracy: 0.0207\n",
            "Epoch 337/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9899 - accuracy: 0.0440 - val_loss: 1.7035 - val_accuracy: 0.0207\n",
            "Epoch 338/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9663 - accuracy: 0.0431 - val_loss: 1.7120 - val_accuracy: 0.0205\n",
            "Epoch 339/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0147 - accuracy: 0.0449 - val_loss: 1.7015 - val_accuracy: 0.0203\n",
            "Epoch 340/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 1.0327 - accuracy: 0.0424 - val_loss: 1.7083 - val_accuracy: 0.0195\n",
            "Epoch 341/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0385 - accuracy: 0.0447 - val_loss: 1.6989 - val_accuracy: 0.0217\n",
            "Epoch 342/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9860 - accuracy: 0.0447 - val_loss: 1.7060 - val_accuracy: 0.0205\n",
            "Epoch 343/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9754 - accuracy: 0.0438 - val_loss: 1.7081 - val_accuracy: 0.0213\n",
            "Epoch 344/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0203 - accuracy: 0.0446 - val_loss: 1.7136 - val_accuracy: 0.0213\n",
            "Epoch 345/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0279 - accuracy: 0.0448 - val_loss: 1.7108 - val_accuracy: 0.0205\n",
            "Epoch 346/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0506 - accuracy: 0.0446 - val_loss: 1.7100 - val_accuracy: 0.0205\n",
            "Epoch 347/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9676 - accuracy: 0.0454 - val_loss: 1.6967 - val_accuracy: 0.0207\n",
            "Epoch 348/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9304 - accuracy: 0.0457 - val_loss: 1.7083 - val_accuracy: 0.0205\n",
            "Epoch 349/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9197 - accuracy: 0.0479 - val_loss: 1.7112 - val_accuracy: 0.0198\n",
            "Epoch 350/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9831 - accuracy: 0.0481 - val_loss: 1.7123 - val_accuracy: 0.0203\n",
            "Epoch 351/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9463 - accuracy: 0.0457 - val_loss: 1.7053 - val_accuracy: 0.0200\n",
            "Epoch 352/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9253 - accuracy: 0.0469 - val_loss: 1.7155 - val_accuracy: 0.0200\n",
            "Epoch 353/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9079 - accuracy: 0.0455 - val_loss: 1.7204 - val_accuracy: 0.0213\n",
            "Epoch 354/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0308 - accuracy: 0.0474 - val_loss: 1.7175 - val_accuracy: 0.0210\n",
            "Epoch 355/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9317 - accuracy: 0.0493 - val_loss: 1.7180 - val_accuracy: 0.0198\n",
            "Epoch 356/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9132 - accuracy: 0.0470 - val_loss: 1.7163 - val_accuracy: 0.0205\n",
            "Epoch 357/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9061 - accuracy: 0.0454 - val_loss: 1.7211 - val_accuracy: 0.0203\n",
            "Epoch 358/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9636 - accuracy: 0.0513 - val_loss: 1.7218 - val_accuracy: 0.0192\n",
            "Epoch 359/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9307 - accuracy: 0.0469 - val_loss: 1.7096 - val_accuracy: 0.0220\n",
            "Epoch 360/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9671 - accuracy: 0.0477 - val_loss: 1.7070 - val_accuracy: 0.0205\n",
            "Epoch 361/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9156 - accuracy: 0.0458 - val_loss: 1.7187 - val_accuracy: 0.0205\n",
            "Epoch 362/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9632 - accuracy: 0.0488 - val_loss: 1.7104 - val_accuracy: 0.0205\n",
            "Epoch 363/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9466 - accuracy: 0.0496 - val_loss: 1.7129 - val_accuracy: 0.0207\n",
            "Epoch 364/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.9261 - accuracy: 0.0489 - val_loss: 1.7185 - val_accuracy: 0.0205\n",
            "Epoch 365/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9125 - accuracy: 0.0502 - val_loss: 1.7148 - val_accuracy: 0.0195\n",
            "Epoch 366/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9997 - accuracy: 0.0525 - val_loss: 1.7213 - val_accuracy: 0.0207\n",
            "Epoch 367/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.9829 - accuracy: 0.0505 - val_loss: 1.7123 - val_accuracy: 0.0203\n",
            "Epoch 368/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9416 - accuracy: 0.0475 - val_loss: 1.7115 - val_accuracy: 0.0203\n",
            "Epoch 369/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9298 - accuracy: 0.0470 - val_loss: 1.7153 - val_accuracy: 0.0205\n",
            "Epoch 370/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9445 - accuracy: 0.0526 - val_loss: 1.7152 - val_accuracy: 0.0200\n",
            "Epoch 371/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 1.0353 - accuracy: 0.0524 - val_loss: 1.7152 - val_accuracy: 0.0203\n",
            "Epoch 372/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9534 - accuracy: 0.0496 - val_loss: 1.7208 - val_accuracy: 0.0215\n",
            "Epoch 373/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.9548 - accuracy: 0.0519 - val_loss: 1.7207 - val_accuracy: 0.0205\n",
            "Epoch 374/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9732 - accuracy: 0.0530 - val_loss: 1.7223 - val_accuracy: 0.0215\n",
            "Epoch 375/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9194 - accuracy: 0.0516 - val_loss: 1.7030 - val_accuracy: 0.0203\n",
            "Epoch 376/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9142 - accuracy: 0.0525 - val_loss: 1.7129 - val_accuracy: 0.0198\n",
            "Epoch 377/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9327 - accuracy: 0.0508 - val_loss: 1.7135 - val_accuracy: 0.0195\n",
            "Epoch 378/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.9644 - accuracy: 0.0533 - val_loss: 1.7126 - val_accuracy: 0.0198\n",
            "Epoch 379/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9453 - accuracy: 0.0519 - val_loss: 1.7219 - val_accuracy: 0.0200\n",
            "Epoch 380/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9642 - accuracy: 0.0545 - val_loss: 1.7160 - val_accuracy: 0.0207\n",
            "Epoch 381/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9391 - accuracy: 0.0535 - val_loss: 1.7199 - val_accuracy: 0.0207\n",
            "Epoch 382/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9000 - accuracy: 0.0544 - val_loss: 1.7198 - val_accuracy: 0.0205\n",
            "Epoch 383/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9363 - accuracy: 0.0541 - val_loss: 1.7227 - val_accuracy: 0.0200\n",
            "Epoch 384/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9379 - accuracy: 0.0548 - val_loss: 1.7147 - val_accuracy: 0.0207\n",
            "Epoch 385/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9315 - accuracy: 0.0544 - val_loss: 1.7302 - val_accuracy: 0.0200\n",
            "Epoch 386/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9750 - accuracy: 0.0587 - val_loss: 1.7202 - val_accuracy: 0.0207\n",
            "Epoch 387/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8562 - accuracy: 0.0568 - val_loss: 1.7249 - val_accuracy: 0.0203\n",
            "Epoch 388/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9221 - accuracy: 0.0557 - val_loss: 1.7300 - val_accuracy: 0.0207\n",
            "Epoch 389/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9778 - accuracy: 0.0582 - val_loss: 1.7180 - val_accuracy: 0.0215\n",
            "Epoch 390/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8905 - accuracy: 0.0581 - val_loss: 1.7270 - val_accuracy: 0.0198\n",
            "Epoch 391/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9566 - accuracy: 0.0565 - val_loss: 1.7198 - val_accuracy: 0.0205\n",
            "Epoch 392/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8876 - accuracy: 0.0539 - val_loss: 1.7207 - val_accuracy: 0.0200\n",
            "Epoch 393/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8889 - accuracy: 0.0583 - val_loss: 1.7275 - val_accuracy: 0.0203\n",
            "Epoch 394/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8772 - accuracy: 0.0568 - val_loss: 1.7263 - val_accuracy: 0.0203\n",
            "Epoch 395/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8998 - accuracy: 0.0554 - val_loss: 1.7217 - val_accuracy: 0.0192\n",
            "Epoch 396/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8673 - accuracy: 0.0560 - val_loss: 1.7235 - val_accuracy: 0.0210\n",
            "Epoch 397/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8648 - accuracy: 0.0599 - val_loss: 1.7246 - val_accuracy: 0.0203\n",
            "Epoch 398/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8609 - accuracy: 0.0579 - val_loss: 1.7230 - val_accuracy: 0.0207\n",
            "Epoch 399/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9101 - accuracy: 0.0602 - val_loss: 1.7209 - val_accuracy: 0.0192\n",
            "Epoch 400/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8734 - accuracy: 0.0591 - val_loss: 1.7313 - val_accuracy: 0.0200\n",
            "Epoch 401/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9066 - accuracy: 0.0638 - val_loss: 1.7243 - val_accuracy: 0.0205\n",
            "Epoch 402/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8034 - accuracy: 0.0585 - val_loss: 1.7173 - val_accuracy: 0.0200\n",
            "Epoch 403/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8216 - accuracy: 0.0594 - val_loss: 1.7218 - val_accuracy: 0.0203\n",
            "Epoch 404/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8490 - accuracy: 0.0596 - val_loss: 1.7185 - val_accuracy: 0.0205\n",
            "Epoch 405/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9471 - accuracy: 0.0595 - val_loss: 1.7146 - val_accuracy: 0.0198\n",
            "Epoch 406/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9215 - accuracy: 0.0572 - val_loss: 1.7274 - val_accuracy: 0.0203\n",
            "Epoch 407/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9145 - accuracy: 0.0599 - val_loss: 1.7247 - val_accuracy: 0.0203\n",
            "Epoch 408/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9573 - accuracy: 0.0659 - val_loss: 1.7285 - val_accuracy: 0.0203\n",
            "Epoch 409/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.9157 - accuracy: 0.0647 - val_loss: 1.7423 - val_accuracy: 0.0210\n",
            "Epoch 410/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9123 - accuracy: 0.0626 - val_loss: 1.7314 - val_accuracy: 0.0198\n",
            "Epoch 411/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8829 - accuracy: 0.0621 - val_loss: 1.7219 - val_accuracy: 0.0207\n",
            "Epoch 412/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8034 - accuracy: 0.0613 - val_loss: 1.7314 - val_accuracy: 0.0198\n",
            "Epoch 413/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8789 - accuracy: 0.0650 - val_loss: 1.7404 - val_accuracy: 0.0192\n",
            "Epoch 414/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8736 - accuracy: 0.0613 - val_loss: 1.7188 - val_accuracy: 0.0195\n",
            "Epoch 415/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8721 - accuracy: 0.0605 - val_loss: 1.7281 - val_accuracy: 0.0200\n",
            "Epoch 416/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8231 - accuracy: 0.0651 - val_loss: 1.7307 - val_accuracy: 0.0205\n",
            "Epoch 417/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8965 - accuracy: 0.0668 - val_loss: 1.7307 - val_accuracy: 0.0210\n",
            "Epoch 418/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8281 - accuracy: 0.0619 - val_loss: 1.7374 - val_accuracy: 0.0205\n",
            "Epoch 419/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9331 - accuracy: 0.0649 - val_loss: 1.7398 - val_accuracy: 0.0213\n",
            "Epoch 420/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8704 - accuracy: 0.0647 - val_loss: 1.7266 - val_accuracy: 0.0215\n",
            "Epoch 421/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.9168 - accuracy: 0.0675 - val_loss: 1.7238 - val_accuracy: 0.0203\n",
            "Epoch 422/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8114 - accuracy: 0.0668 - val_loss: 1.7285 - val_accuracy: 0.0195\n",
            "Epoch 423/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8497 - accuracy: 0.0703 - val_loss: 1.7301 - val_accuracy: 0.0195\n",
            "Epoch 424/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8271 - accuracy: 0.0689 - val_loss: 1.7353 - val_accuracy: 0.0205\n",
            "Epoch 425/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8887 - accuracy: 0.0665 - val_loss: 1.7389 - val_accuracy: 0.0192\n",
            "Epoch 426/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8028 - accuracy: 0.0704 - val_loss: 1.7247 - val_accuracy: 0.0203\n",
            "Epoch 427/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7834 - accuracy: 0.0668 - val_loss: 1.7242 - val_accuracy: 0.0200\n",
            "Epoch 428/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7683 - accuracy: 0.0707 - val_loss: 1.7363 - val_accuracy: 0.0203\n",
            "Epoch 429/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7826 - accuracy: 0.0628 - val_loss: 1.7367 - val_accuracy: 0.0192\n",
            "Epoch 430/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8615 - accuracy: 0.0708 - val_loss: 1.7390 - val_accuracy: 0.0205\n",
            "Epoch 431/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.8093 - accuracy: 0.0708 - val_loss: 1.7356 - val_accuracy: 0.0190\n",
            "Epoch 432/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8593 - accuracy: 0.0723 - val_loss: 1.7442 - val_accuracy: 0.0203\n",
            "Epoch 433/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8000 - accuracy: 0.0718 - val_loss: 1.7362 - val_accuracy: 0.0192\n",
            "Epoch 434/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7972 - accuracy: 0.0683 - val_loss: 1.7311 - val_accuracy: 0.0195\n",
            "Epoch 435/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.8253 - accuracy: 0.0757 - val_loss: 1.7453 - val_accuracy: 0.0207\n",
            "Epoch 436/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8032 - accuracy: 0.0711 - val_loss: 1.7312 - val_accuracy: 0.0192\n",
            "Epoch 437/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8524 - accuracy: 0.0723 - val_loss: 1.7401 - val_accuracy: 0.0203\n",
            "Epoch 438/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.9355 - accuracy: 0.0708 - val_loss: 1.7377 - val_accuracy: 0.0192\n",
            "Epoch 439/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8675 - accuracy: 0.0728 - val_loss: 1.7335 - val_accuracy: 0.0213\n",
            "Epoch 440/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8364 - accuracy: 0.0748 - val_loss: 1.7390 - val_accuracy: 0.0207\n",
            "Epoch 441/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8519 - accuracy: 0.0738 - val_loss: 1.7363 - val_accuracy: 0.0192\n",
            "Epoch 442/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7863 - accuracy: 0.0711 - val_loss: 1.7351 - val_accuracy: 0.0198\n",
            "Epoch 443/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8261 - accuracy: 0.0769 - val_loss: 1.7301 - val_accuracy: 0.0192\n",
            "Epoch 444/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8238 - accuracy: 0.0706 - val_loss: 1.7481 - val_accuracy: 0.0182\n",
            "Epoch 445/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8085 - accuracy: 0.0772 - val_loss: 1.7458 - val_accuracy: 0.0203\n",
            "Epoch 446/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7958 - accuracy: 0.0742 - val_loss: 1.7326 - val_accuracy: 0.0190\n",
            "Epoch 447/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.8125 - accuracy: 0.0766 - val_loss: 1.7418 - val_accuracy: 0.0198\n",
            "Epoch 448/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.8079 - accuracy: 0.0729 - val_loss: 1.7351 - val_accuracy: 0.0188\n",
            "Epoch 449/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.8082 - accuracy: 0.0733 - val_loss: 1.7323 - val_accuracy: 0.0203\n",
            "Epoch 450/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7690 - accuracy: 0.0748 - val_loss: 1.7440 - val_accuracy: 0.0203\n",
            "Epoch 451/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8518 - accuracy: 0.0759 - val_loss: 1.7445 - val_accuracy: 0.0203\n",
            "Epoch 452/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8334 - accuracy: 0.0802 - val_loss: 1.7452 - val_accuracy: 0.0195\n",
            "Epoch 453/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7904 - accuracy: 0.0760 - val_loss: 1.7375 - val_accuracy: 0.0190\n",
            "Epoch 454/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.8576 - accuracy: 0.0794 - val_loss: 1.7585 - val_accuracy: 0.0195\n",
            "Epoch 455/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7531 - accuracy: 0.0776 - val_loss: 1.7446 - val_accuracy: 0.0203\n",
            "Epoch 456/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7414 - accuracy: 0.0766 - val_loss: 1.7410 - val_accuracy: 0.0205\n",
            "Epoch 457/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8107 - accuracy: 0.0774 - val_loss: 1.7467 - val_accuracy: 0.0192\n",
            "Epoch 458/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8088 - accuracy: 0.0780 - val_loss: 1.7447 - val_accuracy: 0.0198\n",
            "Epoch 459/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7894 - accuracy: 0.0809 - val_loss: 1.7432 - val_accuracy: 0.0207\n",
            "Epoch 460/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7997 - accuracy: 0.0776 - val_loss: 1.7543 - val_accuracy: 0.0192\n",
            "Epoch 461/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7742 - accuracy: 0.0799 - val_loss: 1.7513 - val_accuracy: 0.0188\n",
            "Epoch 462/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7495 - accuracy: 0.0815 - val_loss: 1.7419 - val_accuracy: 0.0198\n",
            "Epoch 463/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.8106 - accuracy: 0.0814 - val_loss: 1.7431 - val_accuracy: 0.0190\n",
            "Epoch 464/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7030 - accuracy: 0.0860 - val_loss: 1.7460 - val_accuracy: 0.0203\n",
            "Epoch 465/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7951 - accuracy: 0.0856 - val_loss: 1.7542 - val_accuracy: 0.0185\n",
            "Epoch 466/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7418 - accuracy: 0.0802 - val_loss: 1.7450 - val_accuracy: 0.0198\n",
            "Epoch 467/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7491 - accuracy: 0.0792 - val_loss: 1.7498 - val_accuracy: 0.0190\n",
            "Epoch 468/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.8312 - accuracy: 0.0867 - val_loss: 1.7464 - val_accuracy: 0.0192\n",
            "Epoch 469/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7753 - accuracy: 0.0861 - val_loss: 1.7441 - val_accuracy: 0.0203\n",
            "Epoch 470/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8242 - accuracy: 0.0842 - val_loss: 1.7525 - val_accuracy: 0.0192\n",
            "Epoch 471/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7834 - accuracy: 0.0858 - val_loss: 1.7367 - val_accuracy: 0.0195\n",
            "Epoch 472/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7647 - accuracy: 0.0822 - val_loss: 1.7439 - val_accuracy: 0.0192\n",
            "Epoch 473/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.8285 - accuracy: 0.0858 - val_loss: 1.7522 - val_accuracy: 0.0195\n",
            "Epoch 474/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7691 - accuracy: 0.0850 - val_loss: 1.7539 - val_accuracy: 0.0188\n",
            "Epoch 475/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7378 - accuracy: 0.0883 - val_loss: 1.7376 - val_accuracy: 0.0195\n",
            "Epoch 476/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7590 - accuracy: 0.0859 - val_loss: 1.7520 - val_accuracy: 0.0190\n",
            "Epoch 477/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7561 - accuracy: 0.0865 - val_loss: 1.7441 - val_accuracy: 0.0200\n",
            "Epoch 478/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7390 - accuracy: 0.0827 - val_loss: 1.7640 - val_accuracy: 0.0185\n",
            "Epoch 479/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7403 - accuracy: 0.0878 - val_loss: 1.7558 - val_accuracy: 0.0190\n",
            "Epoch 480/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7367 - accuracy: 0.0868 - val_loss: 1.7582 - val_accuracy: 0.0188\n",
            "Epoch 481/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7376 - accuracy: 0.0904 - val_loss: 1.7436 - val_accuracy: 0.0188\n",
            "Epoch 482/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7315 - accuracy: 0.0877 - val_loss: 1.7454 - val_accuracy: 0.0203\n",
            "Epoch 483/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7108 - accuracy: 0.0864 - val_loss: 1.7495 - val_accuracy: 0.0190\n",
            "Epoch 484/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7160 - accuracy: 0.0848 - val_loss: 1.7538 - val_accuracy: 0.0192\n",
            "Epoch 485/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7032 - accuracy: 0.0844 - val_loss: 1.7475 - val_accuracy: 0.0203\n",
            "Epoch 486/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7333 - accuracy: 0.0846 - val_loss: 1.7495 - val_accuracy: 0.0198\n",
            "Epoch 487/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6845 - accuracy: 0.0838 - val_loss: 1.7532 - val_accuracy: 0.0190\n",
            "Epoch 488/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7570 - accuracy: 0.0837 - val_loss: 1.7518 - val_accuracy: 0.0200\n",
            "Epoch 489/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6742 - accuracy: 0.0915 - val_loss: 1.7576 - val_accuracy: 0.0182\n",
            "Epoch 490/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7054 - accuracy: 0.0903 - val_loss: 1.7412 - val_accuracy: 0.0195\n",
            "Epoch 491/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7124 - accuracy: 0.0856 - val_loss: 1.7591 - val_accuracy: 0.0185\n",
            "Epoch 492/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7255 - accuracy: 0.0877 - val_loss: 1.7658 - val_accuracy: 0.0188\n",
            "Epoch 493/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7086 - accuracy: 0.0865 - val_loss: 1.7599 - val_accuracy: 0.0195\n",
            "Epoch 494/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7275 - accuracy: 0.0895 - val_loss: 1.7598 - val_accuracy: 0.0192\n",
            "Epoch 495/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6963 - accuracy: 0.0889 - val_loss: 1.7555 - val_accuracy: 0.0195\n",
            "Epoch 496/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6671 - accuracy: 0.0906 - val_loss: 1.7520 - val_accuracy: 0.0200\n",
            "Epoch 497/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6895 - accuracy: 0.0909 - val_loss: 1.7432 - val_accuracy: 0.0205\n",
            "Epoch 498/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7133 - accuracy: 0.0896 - val_loss: 1.7561 - val_accuracy: 0.0195\n",
            "Epoch 499/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6714 - accuracy: 0.0933 - val_loss: 1.7458 - val_accuracy: 0.0203\n",
            "Epoch 500/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7477 - accuracy: 0.0933 - val_loss: 1.7718 - val_accuracy: 0.0198\n",
            "Epoch 501/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6784 - accuracy: 0.0904 - val_loss: 1.7628 - val_accuracy: 0.0203\n",
            "Epoch 502/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6653 - accuracy: 0.0916 - val_loss: 1.7611 - val_accuracy: 0.0195\n",
            "Epoch 503/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7625 - accuracy: 0.0943 - val_loss: 1.7664 - val_accuracy: 0.0182\n",
            "Epoch 504/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7091 - accuracy: 0.0928 - val_loss: 1.7379 - val_accuracy: 0.0210\n",
            "Epoch 505/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6960 - accuracy: 0.0878 - val_loss: 1.7647 - val_accuracy: 0.0200\n",
            "Epoch 506/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6503 - accuracy: 0.0903 - val_loss: 1.7563 - val_accuracy: 0.0192\n",
            "Epoch 507/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6979 - accuracy: 0.0985 - val_loss: 1.7487 - val_accuracy: 0.0198\n",
            "Epoch 508/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7270 - accuracy: 0.0945 - val_loss: 1.7700 - val_accuracy: 0.0182\n",
            "Epoch 509/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7106 - accuracy: 0.0962 - val_loss: 1.7490 - val_accuracy: 0.0198\n",
            "Epoch 510/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7222 - accuracy: 0.0943 - val_loss: 1.7558 - val_accuracy: 0.0192\n",
            "Epoch 511/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7266 - accuracy: 0.0981 - val_loss: 1.7557 - val_accuracy: 0.0195\n",
            "Epoch 512/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6525 - accuracy: 0.0929 - val_loss: 1.7538 - val_accuracy: 0.0200\n",
            "Epoch 513/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.7135 - accuracy: 0.0992 - val_loss: 1.7543 - val_accuracy: 0.0203\n",
            "Epoch 514/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6974 - accuracy: 0.0935 - val_loss: 1.7668 - val_accuracy: 0.0188\n",
            "Epoch 515/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7088 - accuracy: 0.0961 - val_loss: 1.7618 - val_accuracy: 0.0188\n",
            "Epoch 516/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7416 - accuracy: 0.0967 - val_loss: 1.7648 - val_accuracy: 0.0190\n",
            "Epoch 517/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6405 - accuracy: 0.0942 - val_loss: 1.7565 - val_accuracy: 0.0198\n",
            "Epoch 518/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6655 - accuracy: 0.0976 - val_loss: 1.7621 - val_accuracy: 0.0188\n",
            "Epoch 519/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6276 - accuracy: 0.0973 - val_loss: 1.7692 - val_accuracy: 0.0190\n",
            "Epoch 520/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6973 - accuracy: 0.0942 - val_loss: 1.7446 - val_accuracy: 0.0192\n",
            "Epoch 521/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.7268 - accuracy: 0.0974 - val_loss: 1.7434 - val_accuracy: 0.0200\n",
            "Epoch 522/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6947 - accuracy: 0.0959 - val_loss: 1.7699 - val_accuracy: 0.0192\n",
            "Epoch 523/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6591 - accuracy: 0.0926 - val_loss: 1.7660 - val_accuracy: 0.0185\n",
            "Epoch 524/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6745 - accuracy: 0.0971 - val_loss: 1.7642 - val_accuracy: 0.0190\n",
            "Epoch 525/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6605 - accuracy: 0.0981 - val_loss: 1.7675 - val_accuracy: 0.0182\n",
            "Epoch 526/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7086 - accuracy: 0.0976 - val_loss: 1.7826 - val_accuracy: 0.0182\n",
            "Epoch 527/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6956 - accuracy: 0.1012 - val_loss: 1.7757 - val_accuracy: 0.0195\n",
            "Epoch 528/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6519 - accuracy: 0.1019 - val_loss: 1.7887 - val_accuracy: 0.0185\n",
            "Epoch 529/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6854 - accuracy: 0.1000 - val_loss: 1.7704 - val_accuracy: 0.0190\n",
            "Epoch 530/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6955 - accuracy: 0.1024 - val_loss: 1.7690 - val_accuracy: 0.0188\n",
            "Epoch 531/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6670 - accuracy: 0.1054 - val_loss: 1.7836 - val_accuracy: 0.0192\n",
            "Epoch 532/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6927 - accuracy: 0.1035 - val_loss: 1.7605 - val_accuracy: 0.0200\n",
            "Epoch 533/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6865 - accuracy: 0.0986 - val_loss: 1.7719 - val_accuracy: 0.0200\n",
            "Epoch 534/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6698 - accuracy: 0.1020 - val_loss: 1.7705 - val_accuracy: 0.0188\n",
            "Epoch 535/600\n",
            "32/32 [==============================] - 1s 21ms/step - loss: 0.7342 - accuracy: 0.1066 - val_loss: 1.7630 - val_accuracy: 0.0195\n",
            "Epoch 536/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6201 - accuracy: 0.0983 - val_loss: 1.7565 - val_accuracy: 0.0200\n",
            "Epoch 537/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7041 - accuracy: 0.1072 - val_loss: 1.7594 - val_accuracy: 0.0205\n",
            "Epoch 538/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6954 - accuracy: 0.1067 - val_loss: 1.7798 - val_accuracy: 0.0195\n",
            "Epoch 539/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6678 - accuracy: 0.1065 - val_loss: 1.7618 - val_accuracy: 0.0203\n",
            "Epoch 540/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.7112 - accuracy: 0.1017 - val_loss: 1.7763 - val_accuracy: 0.0192\n",
            "Epoch 541/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6270 - accuracy: 0.1038 - val_loss: 1.7546 - val_accuracy: 0.0198\n",
            "Epoch 542/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6581 - accuracy: 0.1032 - val_loss: 1.7698 - val_accuracy: 0.0192\n",
            "Epoch 543/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6570 - accuracy: 0.1007 - val_loss: 1.7735 - val_accuracy: 0.0190\n",
            "Epoch 544/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6349 - accuracy: 0.1060 - val_loss: 1.7854 - val_accuracy: 0.0190\n",
            "Epoch 545/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6886 - accuracy: 0.1103 - val_loss: 1.7808 - val_accuracy: 0.0192\n",
            "Epoch 546/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.6559 - accuracy: 0.1110 - val_loss: 1.7928 - val_accuracy: 0.0195\n",
            "Epoch 547/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6395 - accuracy: 0.1039 - val_loss: 1.7759 - val_accuracy: 0.0198\n",
            "Epoch 548/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6797 - accuracy: 0.1044 - val_loss: 1.7835 - val_accuracy: 0.0190\n",
            "Epoch 549/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6222 - accuracy: 0.1064 - val_loss: 1.7756 - val_accuracy: 0.0192\n",
            "Epoch 550/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6907 - accuracy: 0.1060 - val_loss: 1.7703 - val_accuracy: 0.0188\n",
            "Epoch 551/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6326 - accuracy: 0.1018 - val_loss: 1.7836 - val_accuracy: 0.0192\n",
            "Epoch 552/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.5837 - accuracy: 0.1016 - val_loss: 1.7943 - val_accuracy: 0.0182\n",
            "Epoch 553/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6487 - accuracy: 0.1062 - val_loss: 1.7730 - val_accuracy: 0.0188\n",
            "Epoch 554/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6027 - accuracy: 0.1077 - val_loss: 1.7901 - val_accuracy: 0.0192\n",
            "Epoch 555/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6079 - accuracy: 0.1026 - val_loss: 1.7587 - val_accuracy: 0.0203\n",
            "Epoch 556/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6677 - accuracy: 0.1059 - val_loss: 1.7823 - val_accuracy: 0.0182\n",
            "Epoch 557/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6717 - accuracy: 0.1084 - val_loss: 1.7797 - val_accuracy: 0.0195\n",
            "Epoch 558/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6453 - accuracy: 0.1085 - val_loss: 1.7813 - val_accuracy: 0.0188\n",
            "Epoch 559/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6090 - accuracy: 0.1098 - val_loss: 1.7930 - val_accuracy: 0.0195\n",
            "Epoch 560/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6366 - accuracy: 0.1094 - val_loss: 1.7791 - val_accuracy: 0.0190\n",
            "Epoch 561/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6165 - accuracy: 0.1092 - val_loss: 1.7832 - val_accuracy: 0.0188\n",
            "Epoch 562/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6635 - accuracy: 0.1085 - val_loss: 1.7629 - val_accuracy: 0.0198\n",
            "Epoch 563/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6187 - accuracy: 0.1062 - val_loss: 1.7783 - val_accuracy: 0.0190\n",
            "Epoch 564/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6224 - accuracy: 0.1089 - val_loss: 1.7741 - val_accuracy: 0.0200\n",
            "Epoch 565/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6968 - accuracy: 0.1128 - val_loss: 1.7825 - val_accuracy: 0.0200\n",
            "Epoch 566/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6906 - accuracy: 0.1158 - val_loss: 1.7865 - val_accuracy: 0.0200\n",
            "Epoch 567/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6405 - accuracy: 0.1070 - val_loss: 1.7930 - val_accuracy: 0.0200\n",
            "Epoch 568/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6214 - accuracy: 0.1102 - val_loss: 1.7843 - val_accuracy: 0.0200\n",
            "Epoch 569/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6291 - accuracy: 0.1065 - val_loss: 1.7819 - val_accuracy: 0.0203\n",
            "Epoch 570/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6189 - accuracy: 0.1142 - val_loss: 1.7838 - val_accuracy: 0.0200\n",
            "Epoch 571/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6390 - accuracy: 0.1062 - val_loss: 1.7806 - val_accuracy: 0.0190\n",
            "Epoch 572/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6026 - accuracy: 0.1124 - val_loss: 1.7728 - val_accuracy: 0.0210\n",
            "Epoch 573/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6156 - accuracy: 0.1085 - val_loss: 1.7902 - val_accuracy: 0.0195\n",
            "Epoch 574/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.5878 - accuracy: 0.1097 - val_loss: 1.7757 - val_accuracy: 0.0192\n",
            "Epoch 575/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6512 - accuracy: 0.1146 - val_loss: 1.7837 - val_accuracy: 0.0188\n",
            "Epoch 576/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6239 - accuracy: 0.1121 - val_loss: 1.7786 - val_accuracy: 0.0198\n",
            "Epoch 577/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6049 - accuracy: 0.1079 - val_loss: 1.7887 - val_accuracy: 0.0198\n",
            "Epoch 578/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6218 - accuracy: 0.1140 - val_loss: 1.7749 - val_accuracy: 0.0203\n",
            "Epoch 579/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.5969 - accuracy: 0.1136 - val_loss: 1.7902 - val_accuracy: 0.0198\n",
            "Epoch 580/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.5908 - accuracy: 0.1115 - val_loss: 1.7921 - val_accuracy: 0.0190\n",
            "Epoch 581/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6717 - accuracy: 0.1208 - val_loss: 1.7860 - val_accuracy: 0.0182\n",
            "Epoch 582/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6188 - accuracy: 0.1140 - val_loss: 1.7815 - val_accuracy: 0.0198\n",
            "Epoch 583/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6237 - accuracy: 0.1135 - val_loss: 1.7736 - val_accuracy: 0.0190\n",
            "Epoch 584/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.5863 - accuracy: 0.1152 - val_loss: 1.7746 - val_accuracy: 0.0205\n",
            "Epoch 585/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6029 - accuracy: 0.1128 - val_loss: 1.7888 - val_accuracy: 0.0190\n",
            "Epoch 586/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.5803 - accuracy: 0.1122 - val_loss: 1.7844 - val_accuracy: 0.0205\n",
            "Epoch 587/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6491 - accuracy: 0.1159 - val_loss: 1.7841 - val_accuracy: 0.0195\n",
            "Epoch 588/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6361 - accuracy: 0.1209 - val_loss: 1.7783 - val_accuracy: 0.0198\n",
            "Epoch 589/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.6268 - accuracy: 0.1153 - val_loss: 1.7842 - val_accuracy: 0.0188\n",
            "Epoch 590/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.5799 - accuracy: 0.1100 - val_loss: 1.7968 - val_accuracy: 0.0198\n",
            "Epoch 591/600\n",
            "32/32 [==============================] - 1s 18ms/step - loss: 0.5961 - accuracy: 0.1164 - val_loss: 1.7879 - val_accuracy: 0.0198\n",
            "Epoch 592/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.5933 - accuracy: 0.1176 - val_loss: 1.7889 - val_accuracy: 0.0188\n",
            "Epoch 593/600\n",
            "32/32 [==============================] - 1s 20ms/step - loss: 0.5948 - accuracy: 0.1182 - val_loss: 1.7839 - val_accuracy: 0.0198\n",
            "Epoch 594/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6135 - accuracy: 0.1214 - val_loss: 1.7748 - val_accuracy: 0.0200\n",
            "Epoch 595/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.5488 - accuracy: 0.1134 - val_loss: 1.7812 - val_accuracy: 0.0205\n",
            "Epoch 596/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6369 - accuracy: 0.1206 - val_loss: 1.7873 - val_accuracy: 0.0198\n",
            "Epoch 597/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.5923 - accuracy: 0.1203 - val_loss: 1.8035 - val_accuracy: 0.0190\n",
            "Epoch 598/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.6150 - accuracy: 0.1169 - val_loss: 1.7843 - val_accuracy: 0.0207\n",
            "Epoch 599/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.5578 - accuracy: 0.1155 - val_loss: 1.7839 - val_accuracy: 0.0192\n",
            "Epoch 600/600\n",
            "32/32 [==============================] - 1s 19ms/step - loss: 0.5656 - accuracy: 0.1170 - val_loss: 1.7768 - val_accuracy: 0.0200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jkqaGwZvVp-k",
        "outputId": "7d021707-cfff-455c-a066-4488c5da992b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'],label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'],label='val_accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('accuracy.png');"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xMwHzuawV94m",
        "outputId": "e2b5834c-5f9a-44f2-84d7-5b14fa8a0bca"
      },
      "source": [
        "plt.plot(history.history['loss'],label='loss')\n",
        "plt.plot(history.history['val_loss'],label='val_loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST5NJzSwJlDB"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "training_model = load_model('my_model.h5')\n",
        "encoder_inputs = training_model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "latent_dim = 256\n",
        "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
        "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
        "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_hidden, state_cell]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "def decode_response(test_input):\n",
        "    #Getting the output states to pass into the decoder\n",
        "    states_value = encoder_model.predict(test_input)\n",
        "    #Generating empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    #Setting the first token of target sequence with the start token\n",
        "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
        "    \n",
        "    #A variable to store our response word by word\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "          #Predicting output tokens with probabilities and states\n",
        "          output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
        "    #Choosing the one with highest probability\n",
        "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "          sampled_token = reverse_target_features_dict[sampled_token_index]\n",
        "          decoded_sentence += \" \" + sampled_token\n",
        "    #Stop if hit max length or found the stop token\n",
        "          if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "    #Update the target sequence\n",
        "          target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "          target_seq[0, 0, sampled_token_index] = 1.\n",
        "          #Update states\n",
        "          states_value = [hidden_state, cell_state]\n",
        "    return decoded_sentence"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JTKCjKVJ92i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "833e052a-452f-4a94-b9d6-699b50405eb3"
      },
      "source": [
        "class ChatBot:\n",
        "  negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
        "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
        "#Method to start the conversation\n",
        "  def start_chat(self):\n",
        "    user_response = input(\"Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\\n\")\n",
        "    \n",
        "    if user_response in self.negative_responses:\n",
        "      print(\"Ok, have a great day!\")\n",
        "      return\n",
        "    self.chat(user_response)\n",
        "\n",
        "\n",
        "#Method to handle the conversation\n",
        "  def chat(self, reply):\n",
        "    while not self.make_exit(reply):\n",
        "      reply = input(self.generate_response(reply)+\"\\n\")\n",
        "    \n",
        "\n",
        "#Method to convert user input into a matrix\n",
        "  def string_to_matrix(self, user_input):\n",
        "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
        "    user_input_matrix = np.zeros(\n",
        "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
        "      dtype='float32')\n",
        "    for timestep, token in enumerate(tokens):\n",
        "      if token in input_features_dict:\n",
        "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
        "    return user_input_matrix\n",
        "  \n",
        "\n",
        "#Method that will create a response using seq2seq model we built\n",
        "  def generate_response(self, user_input):\n",
        "    input_matrix = self.string_to_matrix(user_input)\n",
        "    chatbot_response = decode_response(input_matrix)\n",
        "    #Remove <START> and <END> tokens from chatbot_response\n",
        "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
        "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
        "    return chatbot_response\n",
        "\n",
        "    \n",
        "#Method to check for exit commands\n",
        "  def make_exit(self, reply):\n",
        "    for exit_command in self.exit_commands:\n",
        "      if exit_command in reply:\n",
        "        print(\"Ok, have a great day!\")\n",
        "        return True\n",
        "    return False\n",
        "  \n",
        "chatbot = ChatBot()\n",
        "chatbot.start_chat()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
            "hi there\n",
            " hi there how are you \n",
            "im fine\n",
            " i m \n",
            "I am fine\n",
            " 8 night \n",
            "nice\n",
            " how is is you \n",
            "all is good\n",
            " let minds \n",
            "what\n",
            " ok \n",
            "how are you\n",
            " i m sorry i t t \n",
            "can you speak english\n",
            " not incredibly something i m \n",
            "good\n",
            " good \n",
            "nice one\n",
            " i m super i m \n",
            "woahh\n",
            " ok \n",
            "you are improving\n",
            " thanks i m \n",
            "great improvement\n",
            " storm \n",
            "storm\n",
            " ok \n",
            "how old are you \n",
            " i m 22 years old i m skinny brown brown to to to \n",
            "where you are living\n",
            " i t you \n",
            "whats your name\n",
            " you you you you \n",
            "what is your name\n",
            " i m just amazed with watch watch a \n",
            "what is your name\n",
            " i m just amazed with watch watch a \n",
            "what can you do\n",
            " i like the english of of you \n",
            "but your english is bad\n",
            " is late difficult a \n",
            "ok got some work\n",
            " only through an api i m \n",
            "i got to go\n",
            " yep what i m i m you \n",
            "okay bye\n",
            "Ok, have a great day!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7J5OMxJKEDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04505f40-a11e-4b27-d54b-7b839a2e3acf"
      },
      "source": [
        "chatbot.start_chat()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
            "hi there\n",
            " hi there how are you \n",
            "i am fine\n",
            " i m sorry i can t interpret a \n",
            "how are you \n",
            " i m sorry i t t \n",
            "are you a human\n",
            " i blow minds \n",
            "nice\n",
            " how is is you \n",
            "fine\n",
            " good 50583239 and \n",
            "where are you\n",
            " i t you \n",
            "excellent\n",
            " ok \n",
            "good\n",
            " good \n",
            "nice\n",
            " how is is you \n",
            "wonderful\n",
            " ok \n",
            "what can you do\n",
            " i like the english of of you \n",
            "can you do\n",
            " yes late is i m \n",
            "who are you \n",
            " and was that you you \n",
            "bye\n",
            "Ok, have a great day!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN9jd7lQqtbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ad3f5c-7b03-4a8e-c706-a8c71ef66f9b"
      },
      "source": [
        "chatbot.start_chat()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
            "yes\n",
            " let minds you \n",
            "hi there\n",
            " hi there how are you \n",
            "fine\n",
            " good 50583239 and \n",
            "good\n",
            " good \n",
            "all is good\n",
            " let minds \n",
            "have a good day\n",
            " is a a smart a \n",
            "bye\n",
            "Ok, have a great day!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_1qCCPKXYG7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}